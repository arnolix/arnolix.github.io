<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Django template 过滤器]]></title>
    <url>%2F2018%2F10%2F26%2FDjango-template-%E8%BF%87%E6%BB%A4%E5%99%A8%2F</url>
    <content type="text"><![CDATA[一、形式：小写1&#123;&#123; name | lower &#125;&#125; 二、过滤器是可以嵌套的，字符串经过三个过滤器，第一个过滤器转换为小写，第二个过滤器输出首字母，第三个过滤器将首字母转换成大写12标签&#123;&#123; str|lower|first|upper &#125;&#125; 三、过滤器的参数显示前30个字1&#123;&#123; bio | truncatewords:&quot;30&quot; &#125;&#125; 格式化1&#123;&#123; pub_date | date:&quot;F j, Y&quot; &#125;&#125; 过滤器列表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112&#123;&#123; 123|add:&quot;5&quot; &#125;&#125; 给value加上一个数值&#123;&#123; &quot;AB&apos;CD&quot;|addslashes &#125;&#125; 单引号加上转义号，一般用于输出到javascript中&#123;&#123; &quot;abcd&quot;|capfirst &#125;&#125; 第一个字母大写&#123;&#123; &quot;abcd&quot;|center:&quot;50&quot; &#125;&#125; 输出指定长度的字符串，并把值对中&#123;&#123; &quot;123spam456spam789&quot;|cut:&quot;spam&quot; &#125;&#125; 查找删除指定字符串&#123;&#123; value|date:&quot;F j, Y&quot; &#125;&#125; 格式化日期&#123;&#123; value|default:&quot;(N/A)&quot; &#125;&#125; 值不存在，使用指定值&#123;&#123; value|default_if_none:&quot;(N/A)&quot; &#125;&#125; 值是None，使用指定值&#123;&#123; 列表变量|dictsort:&quot;数字&quot; &#125;&#125; 排序从小到大&#123;&#123; 列表变量|dictsortreversed:&quot;数字&quot; &#125;&#125; 排序从大到小&#123;% if 92|pisibleby:&quot;2&quot; %&#125; 判断是否整除指定数字&#123;&#123; string|escape &#125;&#125; 转换为html实体&#123;&#123; 21984124|filesizeformat &#125;&#125; 以1024为基数，计算最大值，保留1位小数，增加可读性&#123;&#123; list|first &#125;&#125; 返回列表第一个元素&#123;&#123; &quot;ik23hr&amp;jqwh&quot;|fix_ampersands &#125;&#125; &amp;转为&amp;&#123;&#123; 13.414121241|floatformat &#125;&#125; 保留1位小数，可为负数，几种形式&#123;&#123; 13.414121241|floatformat:&quot;2&quot; &#125;&#125; 保留2位小数&#123;&#123; 23456 |get_digit:&quot;1&quot; &#125;&#125; 从个位数开始截取指定位置的1个数字&#123;&#123; list|join:&quot;, &quot; &#125;&#125; 用指定分隔符连接列表&#123;&#123; list|length &#125;&#125; 返回列表个数&#123;% if 列表|length_is:&quot;3&quot; %&#125; 列表个数是否指定数值&#123;&#123; &quot;ABCD&quot;|linebreaks &#125;&#125; value中的&quot;\n&quot;将被&lt;br/&gt;替代，并且整个value使用&lt;/p&gt;包围起来，从而适和HTML的格式&#123;&#123; &quot;ABCD&quot;|linebreaksbr &#125;&#125; value中的&quot;\n&quot;将被&lt;br/&gt;替代&#123;&#123; 变量|linenumbers &#125;&#125; 为变量中每一行加上行号&#123;&#123; &quot;abcd&quot;|ljust:&quot;50&quot; &#125;&#125; 把字符串在指定宽度中对左，其它用空格填充&#123;&#123; &quot;ABCD&quot;|lower &#125;&#125; 小写&#123;% for i in &quot;1abc1&quot;|make_list %&#125;ABCDE,&#123;% endfor %&#125; 把字符串或数字的字符个数作为一个列表&#123;&#123; &quot;abcdefghijklmnopqrstuvwxyz&quot;|phone2numeric &#125;&#125; 把字符转为可以对应的数字？？&#123;&#123; 列表或数字|pluralize &#125;&#125; 单词的复数形式，如列表字符串个数大于1，返回s，否则返回空串&#123;&#123; 列表或数字|pluralize:&quot;es&quot; &#125;&#125; 指定es&#123;&#123; 列表或数字|pluralize:&quot;y,ies&quot; &#125;&#125; 指定ies替换为y&#123;&#123; object|pprint &#125;&#125; 显示一个对象的值&#123;&#123; 列表|random &#125;&#125; 返回列表的随机一项&#123;&#123; string|removetags:&quot;br p p&quot; &#125;&#125; 删除字符串中指定html标记&#123;&#123; string|rjust:&quot;50&quot; &#125;&#125; 把字符串在指定宽度中对右，其它用空格填充&#123;&#123; 列表|slice:&quot;:2&quot; &#125;&#125; 切片&#123;&#123; string|slugify &#125;&#125; 字符串中留下减号和下划线，其它符号删除，空格用减号替换&#123;&#123; 3|stringformat:&quot;02i&quot; &#125;&#125; 字符串格式，使用Python的字符串格式语法&#123;&#123; &quot;EABCD&quot;|striptags &#125;&#125; 剥去[X]HTML语法标记&#123;&#123; 时间变量|time:&quot;P&quot; &#125;&#125; 日期的时间部分格式&#123;&#123; datetime|timesince &#125;&#125; 给定日期到现在过去了多少时间&#123;&#123; datetime|timesince:&quot;other_datetime&quot; &#125;&#125; 两日期间过去了多少时间&#123;&#123; datetime|timeuntil &#125;&#125; 给定日期到现在过去了多少时间，与上面的区别在于2日期的前后位置。&#123;&#123; datetime|timeuntil:&quot;other_datetime&quot; &#125;&#125; 两日期间过去了多少时间&#123;&#123; &quot;abdsadf&quot;|title &#125;&#125; 首字母大写&#123;&#123; &quot;A B C D E F&quot;|truncatewords:&quot;3&quot; &#125;&#125; 截取指定个数的单词&#123;&#123; &quot;111221&quot;|truncatewords_html:&quot;2&quot; &#125;&#125; 截取指定个数的html标记，并补完整 &#123;&#123; list|unordered_list &#125;&#125;多重嵌套列表展现为html的无序列表&#123;&#123; string|upper &#125;&#125; 全部大写linkage url编码&#123;&#123; string|urlize &#125;&#125; 将URLs由纯文本变为可点击的链接。 &#123;&#123; string|urlizetrunc:&quot;30&quot; &#125;&#125; 同上，多个截取字符数。 &#123;&#123; &quot;B C D E F&quot;|wordcount &#125;&#125; 单词数&#123;&#123; &quot;a b c d e f g h i j k&quot;|wordwrap:&quot;5&quot; &#125;&#125; 每指定数量的字符就插入回车符&#123;&#123; boolean|yesno:&quot;Yes,No,Perhaps&quot; &#125;&#125; 对三种值的返回字符串，对应是 非空,空,None。]]></content>
      <categories>
        <category>django</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[requests]]></title>
    <url>%2F2018%2F09%2F20%2Frequests%2F</url>
    <content type="text"><![CDATA[官方原文链接 如果你正在开发基于 REST 的 web API 服务…… 应该忽略 request.POST。— Malcom Tredinnick，Django 开发组 REST framework 的 Request 类扩展与标准的 HttpRequest，并做了相应的增强，比如更加灵活的请求解析（request parsing）和认证（request authentication）。 Request 解析REST framwork 的 Request 对象提供了灵活的请求解析，允许你使用 JSON data 或 其他 media types 像通常处理表单数据一样处理请求。 .datarequest.data 返回请求主题的解析内容。这跟标准的 request.POST 和 request.FILES 类似，并且还具有以下特点： 包括所有解析的内容，文件（file） 和 非文件（non-file inputs）。 支持解析 POST 以外的 HTTP method ， 比如 PUT， PATCH。 更加灵活，不仅仅支持表单数据，传入同样的 JSON 数据一样可以正确解析，并且不用做额外的处理（意思是前端不管提交的是表单数据，还是 JSON 数据，.data 都能够正确解析）。 .data 具体操作，以后再说～ .query_paramsrequest.query_params 等同于 request.GET，不过其名字更加容易理解。 为了代码更加清晰可读，推荐使用 request.query_params ，而不是 Django 中的 request.GET，这样那够让你的代码更加明显的体现出 —– 任何 HTTP method 类型都可能包含查询参数（query parameters），而不仅仅只是 ‘GET’ 请求。 .parsersAPIView 类或者 @api_view 装饰器将根据视图上设置的 parser_classes 或 settings 文件中的 DEFAULT_PARSER_CLASSES 设置来确保此属性（.parsers）自动设置为 Parser 实例列表。 通常不需要关注该属性…… 如果你非要看看它里面是什么，可以打印出来看看，大概长这样：1[&lt;rest_framework.parsers.JSONParser object at 0x7fa850202d68&gt;, &lt;rest_framework.parsers.FormParser object at 0x7fa850202be0&gt;, &lt;rest_framework.parsers.MultiPartParser object at 0x7fa850202860&gt;] 恩，包含三个解析器 JSONParser，FormParser，MultiPartParser。 注意： 如果客户端发送格式错误的内容，则访问 request.data 可能会引发 ParseError 。默认情况下， REST framework 的 APIView 类或者 @api_view 装饰器将捕获错误并返回 400 Bad Request 响应。如果客户端发送的请求内容无法解析（不同于格式错误），则会引发 UnsupportedMediaType 异常，默认情况下会被捕获并返回 415 Unsupported Media Type 响应。 内容协商该请求公开了一些属性，允许你确定内容协商阶段的结果。这使你可以实施一些行为，例如为不同媒体类型选择不同的序列化方案。 .accepted_renderer渲染器实例是由内容协商阶段选择的。 .accepted_media_type表示内容协商阶段接受的 media type 的字符串。 认证（Authentication）REST framework 提供了灵活的认证方式： 可以在 API 的不同部分使用不同的认证策略。 支持同时使用多个身份验证策略。 提供与传入请求关联的用户（user）和令牌（token）信息。 .userrequest.user 通常会返回 django.contrib.auth.models.User 的一个实例，但其行为取决于正在使用的身份验证策略。 如果请求未经身份验证，则 request.user 的默认值是 django.contrib.auth.models.AnonymousUser 的实例（就是匿名用户）。 关于 .user 的更多内容，以后再说～ .authrequest.auth 返回任何附加的认证上下文（authentication context）。request.auth 的确切行为取决于正在使用的身份验证策略，但它通常可能是请求经过身份验证的令牌（token）实例。 如果请求未经身份验证，或者没有附加上下文（context），则 request.auth 的默认值为 None。 关于 .auth 的更多内容，以后再说～ .authenticatorsAPIView 类或 @api_view 装饰器将确保根据视图上设置的 authentication_classes 或基于 settings 文件中的 DEFAULT_AUTHENTICATORS 设置将此属性（.authenticators）自动设置为 Authentication 实例列表。 通常不需要关注该属性…… 注意：调用 .user 或 .auth 属性时可能会引发 WrappedAttributeError 异常。这些错误源于 authenticator 作为一个标准的 AttributeError ，为了防止它们被外部属性访问修改，有必要重新提升为不同的异常类型。Python 无法识别来自 authenticator 的 AttributeError，并会立即假定请求对象没有 .user 或 .auth 属性。authenticator 需要修复。 多说几句 .authenticators 其实存的就是当前使用的认证器（authenticator）列表，打印出来大概是这样： 1[&lt;rest_framework.authentication.SessionAuthentication object at 0x7f8ae4528710&gt;, &lt;rest_framework.authentication.BasicAuthentication object at 0x7f8ae45286d8&gt;] 可以看到这里使用的认证器（authenticator）包括 SessionAuthentication 和 BasicAuthentication。 浏览器增强REST framework 支持基于浏览器的 PUT，PATCH，DELETE 表单。 .methodrequest.method 返回请求 HTTP 方法的大写字符串表示形式。如 GET,POST…。 透明地支持基于浏览器的 PUT，PATCH 和 DELETE 表单。 更多相关信息以后再说～ .content_typerequest.content_type 返回表示 HTTP 请求正文的媒体类型（media type）的字符串对象（比如： text/plain , text/html 等），如果没有提供媒体类型，则返回空字符串。 通常不需要直接访问此属性，一般都依赖与 REST 框架的默认请求解析行为。 不建议使用 request.META.get(&#39;HTTP_CONTENT_TYPE&#39;) 来获取 content type 。 更多相关信息以后再说～ .streamrequest.stream 返回一个代表请求主体内容的流。 通常不需要直接访问此属性，一般都依赖与 REST 框架的默认请求解析行为。 标准的 HttpRequest 属性由于 REST framework 的 Request 扩展于 Django 的 HttpRequest，所有其他标准属性和方法也可用。例如request.META 和 request.session 字典都可以正常使用。 请注意，由于实现原因，Request 类不会从 HttpRequest 类继承，而是使用组合扩展类（优先使用组合，而非继承，恩，老铁没毛病 0.0）]]></content>
      <categories>
        <category>restframework</category>
      </categories>
      <tags>
        <tag>requests, django, restframework, djangorestframework</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[filtering]]></title>
    <url>%2F2018%2F09%2F10%2Ffiltering%2F</url>
    <content type="text"><![CDATA[官方原文链接 过滤REST framework 的通用列表视图的默认行为是从模型管理器返回整个查询集。通常你会希望 API 限制查询集返回的条目。 筛选 GenericAPIView 子类的查询集的最简单方法是重写 .get_queryset() 方法。 重写此方法允许你以多种不同方式自定义视图返回的查询集。 根据当前用户进行过滤你可能需要过滤查询集，以确保只返回与当前通过身份验证的用户发出的请求相关的结果。 你可以基于 request.user 的值进行筛选来完成此操作。 例如： 1234567891011121314from myapp.models import Purchasefrom myapp.serializers import PurchaseSerializerfrom rest_framework import genericsclass PurchaseList(generics.ListAPIView): serializer_class = PurchaseSerializer def get_queryset(self): """ This view should return a list of all the purchases for the currently authenticated user. """ user = self.request.user return Purchase.objects.filter(purchaser=user) 根据 URL 进行过滤另一种过滤方式可能涉及基于 URL 的某个部分限制查询集。 例如，如果你的 URL 配置包含这样的条目： 1url('^purchases/(?P&lt;username&gt;.+)/$', PurchaseList.as_view()), 然后，你可以编写一个视图，返回由 URL 的用户名部分过滤的 purchase 查询集： 12345678910class PurchaseList(generics.ListAPIView): serializer_class = PurchaseSerializer def get_queryset(self): """ This view should return a list of all the purchases for the user as determined by the username portion of the URL. """ username = self.kwargs['username'] return Purchase.objects.filter(purchaser__username=username) 根据查询参数进行过滤过滤初始查询集的最后一个例子是根据 url 中的查询参数确定初始查询集。 我们可以覆盖 .get_queryset() 来处理诸如 http://example.com/api/purchases?username=denvercoder9 的URL，并且只有在 URL 中包含 username 参数时才过滤查询集： 12345678910111213class PurchaseList(generics.ListAPIView): serializer_class = PurchaseSerializer def get_queryset(self): """ Optionally restricts the returned purchases to a given user, by filtering against a `username` query parameter in the URL. """ queryset = Purchase.objects.all() username = self.request.query_params.get('username', None) if username is not None: queryset = queryset.filter(purchaser__username=username) return queryset 通用过滤器除了能够覆盖默认的查询集外，REST framework 还包括对通用过滤后端的支​​持，使你可以轻松构建复杂的搜索和过滤器。 通用过滤器也可以在可浏览的 API 和管理 API 中将自己渲染为 HTML 控件。 设置过滤器后端可以使用 DEFAULT_FILTER_BACKENDS setting 全局设置默认的过滤器后端。例如。 123REST_FRAMEWORK = &#123; 'DEFAULT_FILTER_BACKENDS': ('django_filters.rest_framework.DjangoFilterBackend',)&#125; 你还可以使用基于 GenericAPIView 类的视图，在每个视图或视图集的基础上设置过滤器后端。 123456789import django_filters.rest_frameworkfrom django.contrib.auth.models import Userfrom myapp.serializers import UserSerializerfrom rest_framework import genericsclass UserListView(generics.ListAPIView): queryset = User.objects.all() serializer_class = UserSerializer filter_backends = (django_filters.rest_framework.DjangoFilterBackend,) 过滤和对象查找请注意，如果为一个视图配置了一个过滤器后端，那么除了用于筛选列表视图之外，它还将用于筛选返回单个对象的查询集。 例如，根据前面的示例以及 ID 为 4675 的产品，以下 URL 将返回相应的对象，或返回 404 响应，具体取决于给定产品实例是否满足过滤条件： 1http://example.com/api/products/4675/?category=clothing&amp;max_price=10.00 覆盖初始查询集请注意，你可以同时重写的 .get_queryset() 和通用过滤，并且所有内容都将按预期工作。例如，如果产品与用户具有多对多关系，则可能需要编写一个如下所示的视图： 123456789101112class PurchasedProductsList(generics.ListAPIView): """ Return a list of all the products that the authenticated user has ever purchased, with optional filtering. """ model = Product serializer_class = ProductSerializer filter_class = ProductFilter def get_queryset(self): user = self.request.user return user.purchase_set.all() API 参考DjangoFilterBackenddjango-filter 库包含一个 DjangoFilterBackend 类，它支持 REST framework 对字段过滤进行高度定制。 要使用 DjangoFilterBackend，首先安装 django-filter。然后将 django_filters 添加到 Django 的 INSTALLED_APPS 中 1pip install django-filter 你现在应该将过滤器后端添加到设置中： 123REST_FRAMEWORK = &#123; 'DEFAULT_FILTER_BACKENDS': ('django_filters.rest_framework.DjangoFilterBackend',)&#125; 或者将过滤器后端添加到单个视图或视图集。 12345from django_filters.rest_framework import DjangoFilterBackendclass UserListView(generics.ListAPIView): ... filter_backends = (DjangoFilterBackend,) 如果你只需要简单的基于等式的过滤，则可以在视图或视图集上设置 filter_fields 属性，列出你要过滤的一组字段。 12345class ProductList(generics.ListAPIView): queryset = Product.objects.all() serializer_class = ProductSerializer filter_backends = (DjangoFilterBackend,) filter_fields = ('category', 'in_stock') 这将自动为给定字段创建一个 FilterSet 类，并允许你发出如下请求： 1http://example.com/api/products?category=clothing&amp;in_stock=True 对于更高级的过滤要求，你应该在视图上在指定 FilterSet 类。你可以在 django-filter 文档中阅读有关 FilterSet 的更多信息。还建议你阅读 DRF integration。 SearchFilterSearchFilter 类支持简单的基于单个查询参数的搜索，并且基于 Django 管理员的搜索功能。 在使用时，可浏览的 API 将包含一个 SearchFilter 控件： SearchFilter 类将仅在视图具有 search_fields 属性集的情况下应用。search_fields 属性应该是模型上文本类型字段的名称列表，例如 CharField 或 TextField。 12345class UserListView(generics.ListAPIView): queryset = User.objects.all() serializer_class = UserSerializer filter_backends = (filters.SearchFilter,) search_fields = ('username', 'email') 这将允许客户端通过查询来过滤列表中的项目，例如： 1http://example.com/api/users?search=russell 你还可以使用查找 API 双下划线表示法对 ForeignKey 或 ManyToManyField 执行相关查找： 1search_fields = ('username', 'email', 'profile__profession') 默认情况下，搜索将使用不区分大小写的部分匹配。搜索参数可能包含多个搜索词，它们应该是空格和（或）逗号分隔的。如果使用多个搜索条件，则只有在所有提供的条件匹配的情况下，对象才会返回到列表中。 搜索行为可以通过将各种字符预先添加到 search_fields 来限制。 ‘^’ 匹配起始部分。 ‘=’ 完全匹配。 ‘@’ 全文搜索。（目前只支持 Django 的 MySQL 后端。） ‘$’ 正则匹配。 例如： 1search_fields = ('=username', '=email') 默认情况下，搜索参数被命名为 &#39;search&#39; ，但这可能会被 SEARCH_PARAM setting 覆盖。 有关更多详细信息，请参阅 Django 文档。 OrderingFilterOrderingFilter 类支持简单查询参数控制结果的排序。 默认情况下，查询参数被命名为 &#39;ordering&#39;，但这可能会被 ORDERING_PARAM setting 覆盖。 例如，要通过 username 对用户排序： 1http://example.com/api/users?ordering=username 客户端也可以通过在字段名称前加 ‘ - ‘ 来指定反向排序，如下所示： 1http://example.com/api/users?ordering=-username 也可以指定多个排序： 1http://example.com/api/users?ordering=account,username 指定可以根据哪些字段进行排序建议你明确指定 API 应该允许在排序过滤器中使用哪些字段。你可以通过在视图上设置一个 ordering_fields 属性来完成此操作，如下所示： 12345class UserListView(generics.ListAPIView): queryset = User.objects.all() serializer_class = UserSerializer filter_backends = (filters.OrderingFilter,) ordering_fields = ('username', 'email') 这有助于防止意外的数据泄漏，例如允许用户根据密码哈希字段或其他敏感数据进行排序。 如果你未在视图上指定 ordering_fields 属性，则过滤器类将默认允许用户过滤由 serializer_class 属性指定的序列化类中的任何可读字段。 如果你确信视图使用的查询集不包含任何敏感数据，则还可以通过使用特殊值 &#39;__all__&#39; 明确指定视图允许在任何模型字段或查询集聚合上进行排序。 12345class BookingsListView(generics.ListAPIView): queryset = Booking.objects.all() serializer_class = BookingSerializer filter_backends = (filters.OrderingFilter,) ordering_fields = '__all__' 指定默认顺序如果在视图上设置了 ordering 属性，则将用作默认排序。 通常情况下，你应该通过在初始查询集上设置 order_by 来控制此操作，但是通过在视图上使用 ordering 参数，你可以指定排序方式，然后可以将其作为上下文自动传递到渲染的模板。这可以自动渲染列标题，如果它们用于排序结果。 123456class UserListView(generics.ListAPIView): queryset = User.objects.all() serializer_class = UserSerializer filter_backends = (filters.OrderingFilter,) ordering_fields = ('username', 'email') ordering = ('username',) ordering 属性可以是一个字符串或者字符串列表（元组）。 DjangoObjectPermissionsFilterDjangoObjectPermissionsFilter 旨在与 django-guardian 软件包一起使用，添加了自定义 &#39;view&#39; 的权限。过滤器将确保查询集仅返回用户具有适当查看权限的对象。 如果你使用的是 DjangoObjectPermissionsFilter，那么你可能还需要添加适当的对象权限类，以确保用户只有在具有适当对象权限的情况下才能对实例进行操作。做到这一点的最简单方法是继承 DjangoObjectPermissions 并为 perms_map 属性添加 &#39;view&#39; 权限。 使用 DjangoObjectPermissionsFilter 和 DjangoObjectPermissions 的完整示例可能如下所示。 permissions.py: 12345678910111213class CustomObjectPermissions(permissions.DjangoObjectPermissions): """ Similar to `DjangoObjectPermissions`, but adding 'view' permissions. """ perms_map = &#123; 'GET': ['%(app_label)s.view_%(model_name)s'], 'OPTIONS': ['%(app_label)s.view_%(model_name)s'], 'HEAD': ['%(app_label)s.view_%(model_name)s'], 'POST': ['%(app_label)s.add_%(model_name)s'], 'PUT': ['%(app_label)s.change_%(model_name)s'], 'PATCH': ['%(app_label)s.change_%(model_name)s'], 'DELETE': ['%(app_label)s.delete_%(model_name)s'], &#125; views.py: 12345678910class EventViewSet(viewsets.ModelViewSet): """ Viewset that only lists events if user has 'view' permissions, and only allows operations on individual events if user has appropriate 'view', 'add', 'change' or 'delete' permissions. """ queryset = Event.objects.all() serializer_class = EventSerializer filter_backends = (filters.DjangoObjectPermissionsFilter,) permission_classes = (myapp.permissions.CustomObjectPermissions,) 自定义通用过滤器你还可以提供自己的通用过滤器后端，或者编写一个可供其他开发人员使用的可安装应用程序。 为此，请继承 BaseFilterBackend，并覆盖 .filter_queryset(self, request, queryset, view) 方法。该方法应该返回一个新的，过滤的查询集。 除了允许客户端执行搜索和过滤外，通用过滤器后端可用于限制哪些对象应该对给定的请求或用户可见。 举个栗子你可能需要限制用户只能看到他们创建的对象。 123456class IsOwnerFilterBackend(filters.BaseFilterBackend): """ Filter that only allows users to see their own objects. """ def filter_queryset(self, request, queryset, view): return queryset.filter(owner=request.user) 我们可以通过覆盖视图上的 get_queryset()来实现相同的行为，但使用过滤器后端允许你更轻松地将此限制添加到多个视图，或者将其应用于整个 API。 自定义接口通用过滤器也可以在可浏览的 API 中渲染接口。为此，你应该实现一个 to_html() 方法，该方法返回过滤器的渲染 HTML 表示。此方法应具有以下签名： to_html(self, request, queryset, view) 该方法应该返回一个渲染的 HTML 字符串。 Pagination &amp; schemas通过实现 get_schema_fields() 方法，你还可以使过滤器控件可用于 REST framework 提供的模式自动生成。此方法应具有以下签名： get_schema_fields(self, view) 该方法应该返回一个 coreapi.Field 实例列表。]]></content>
      <categories>
        <category>restframework</category>
      </categories>
      <tags>
        <tag>filtering, restframework, djangoframework, drf, drf-filtering</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx之location和rewrite详解]]></title>
    <url>%2F2018%2F06%2F20%2Fnginx%E4%B9%8Blocation%E5%92%8Crewrite%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[1. location正则写法一个示例：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051location = / &#123; # 精确匹配 / ，主机名后面不能带任何字符串 [ configuration A ]&#125;location / &#123; # 因为所有的地址都以 / 开头，所以这条规则将匹配到所有请求 # 但是正则和最长字符串会优先匹配 [ configuration B ]&#125;location /documents/ &#123; # 匹配任何以 /documents/ 开头的地址，匹配符合以后，还要继续往下搜索 # 只有后面的正则表达式没有匹配到时，这一条才会采用这一条 [ configuration C ]&#125;location ~ /documents/Abc &#123; # 匹配任何以 /documents/Abc 开头的地址，匹配符合以后，还要继续往下搜索 # 只有后面的正则表达式没有匹配到时，这一条才会采用这一条 [ configuration CC ]&#125;location ^~ /images/ &#123; # 匹配任何以 /images/ 开头的地址，匹配符合以后，停止往下搜索正则，采用这一条。 [ configuration D ]&#125;location ~* \.(gif|jpg|jpeg)$ &#123; # 匹配所有以 gif,jpg或jpeg 结尾的请求 # 然而，所有请求 /images/ 下的图片会被 config D 处理，因为 ^~ 到达不了这一条正则 [ configuration E ]&#125;location /images/ &#123; # 字符匹配到 /images/，继续往下，会发现 ^~ 存在 [ configuration F ]&#125;location /images/abc &#123; # 最长字符匹配到 /images/abc，继续往下，会发现 ^~ 存在 # F与G的放置顺序是没有关系的 [ configuration G ]&#125;location ~ /images/abc/ &#123; # 只有去掉 config D 才有效：先最长匹配 config G 开头的地址，继续往下搜索，匹配到这一条正则，采用 [ configuration H ]&#125;location ~* /js/.*/\.js 已=开头表示精确匹配如 A 中只匹配根目录结尾的请求，后面不能带任何字符串。^~ 开头表示uri以某个常规字符串开头，不是正则匹配~ 开头表示区分大小写的正则匹配;~* 开头表示不区分大小写的正则匹配/ 通用匹配, 如果没有其它匹配,任何请求都会匹配到顺序 no优先级：(location =) &gt; (location 完整路径) &gt; (location ^~ 路径) &gt; (location ~,~* 正则顺序) &gt; (location 部分起始路径) &gt; (/) 上面的匹配结果按照上面的location写法，以下的匹配示例成立： / -&gt; config A精确完全匹配，即使/index.html也匹配不了/downloads/download.html -&gt; config B匹配B以后，往下没有任何匹配，采用B/images/1.gif -&gt; configuration D匹配到F，往下匹配到D，停止往下/images/abc/def -&gt; config D最长匹配到G，往下匹配D，停止往下你可以看到 任何以/images/开头的都会匹配到D并停止，FG写在这里是没有任何意义的，H是永远轮不到的，这里只是为了说明匹配顺序/documents/document.html -&gt; config C匹配到C，往下没有任何匹配，采用C/documents/1.jpg -&gt; configuration E匹配到C，往下正则匹配到E/documents/Abc.jpg -&gt; config CC最长匹配到C，往下正则顺序匹配到CC，不会往下到E实际使用建议123456789101112131415161718192021个人觉得至少有三个匹配规则定义，如下：#直接匹配网站根，通过域名访问网站首页比较频繁，使用这个会加速处理，官网如是说。#这里是直接转发给后端应用服务器了，也可以是一个静态首页# 第一个必选规则location = / &#123; proxy_pass http://tomcat:8080/index&#125;# 第二个必选规则是处理静态文件请求，这是nginx作为http服务器的强项# 有两种配置模式，目录匹配或后缀匹配,任选其一或搭配使用location ^~ /static/ &#123; root /webroot/static/;&#125;location ~* \.(gif|jpg|jpeg|png|css|js|ico)$ &#123; root /webroot/res/;&#125;#第三个规则就是通用规则，用来转发动态请求到后端应用服务器#非静态文件请求就默认是动态请求，自己根据实际把握#毕竟目前的一些框架的流行，带.php,.jsp后缀的情况很少了location / &#123; proxy_pass http://tomcat:8080/&#125; http://tengine.taobao.org/book/chapter_02.htmlhttp://nginx.org/en/docs/http/ngx_http_rewrite_module.html 2. Rewrite规则rewrite功能就是，使用nginx提供的全局变量或自己设置的变量，结合正则表达式和标志位实现url重写以及重定向。rewrite只能放在server{},location{},if{}中，并且只能对域名后边的除去传递的参数外的字符串起作用，例如 http://seanlook.com/a/we/index.php?id=1&amp;u=str 只对/a/we/index.php重写。语法rewrite regex replacement [flag]; 如果相对域名或参数字符串起作用，可以使用全局变量匹配，也可以使用proxy_pass反向代理。 表明看rewrite和location功能有点像，都能实现跳转，主要区别在于rewrite是在同一域名内更改获取资源的路径，而location是对一类路径做控制访问或反向代理，可以proxy_pass到其他机器。很多情况下rewrite也会写在location里，它们的执行顺序是： 执行server块的rewrite指令执行location匹配执行选定的location中的rewrite指令如果其中某步URI被重写，则重新循环执行1-3，直到找到真实存在的文件；循环超过10次，则返回500 Internal Server Error错误。 2.1 flag标志位last : 相当于Apache的[L]标记，表示完成rewritebreak : 停止执行当前虚拟主机的后续rewrite指令集redirect : 返回302临时重定向，地址栏会显示跳转后的地址permanent : 返回301永久重定向，地址栏会显示跳转后的地址因为301和302不能简单的只返回状态码，还必须有重定向的URL，这就是return指令无法返回301,302的原因了。这里 last 和 break 区别有点难以理解： last一般写在server和if中，而break一般使用在location中last不终止重写后的url匹配，即新的url会再从server走一遍匹配流程，而break终止重写后的匹配break和last都能组织继续执行后面的rewrite指令 2.2 if指令与全局变量if判断指令语法为if(condition){…}，对给定的条件condition进行判断。如果为真，大括号内的rewrite指令将被执行，if条件(conditon)可以是如下任何内容： 当表达式只是一个变量时，如果值为空或任何以0开头的字符串都会当做false直接比较变量和内容时，使用=或!=~正则表达式匹配，~*不区分大小写的匹配，!~区分大小写的不匹配-f和!-f用来判断是否存在文件-d和!-d用来判断是否存在目录-e和!-e用来判断是否存在文件或目录-x和!-x用来判断文件是否可执行 例如：12345678910111213141516171819202122232425262728293031if ($http_user_agent ~ MSIE) &#123; rewrite ^(.*)$ /msie/$1 break;&#125; //如果UA包含"MSIE"，rewrite请求到/msid/目录下if ($http_cookie ~* "id=([^;]+)(?:;|$)") &#123; set $id $1; &#125; //如果cookie匹配正则，设置变量$id等于正则引用部分if ($request_method = POST) &#123; return 405;&#125; //如果提交方法为POST，则返回状态405（Method not allowed）。return不能返回301,302if ($slow) &#123; limit_rate 10k;&#125; //限速，$slow可以通过 set 指令设置if (!-f $request_filename)&#123; break; proxy_pass http://127.0.0.1;&#125; //如果请求的文件名不存在，则反向代理到localhost 。这里的break也是停止rewrite检查if ($args ~ post=140)&#123; rewrite ^ http://example.com/ permanent;&#125; //如果query string中包含"post=140"，永久重定向到example.comlocation ~* \.(gif|jpg|png|swf|flv)$ &#123; valid_referers none blocked www.jefflei.com www.leizhenfang.com; if ($invalid_referer) &#123; return 404; &#125; //防盗链&#125; 全局变量123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869下面是可以用作if判断的全局变量$args #请求中的参数值$query_string #同 $args$arg_NAME #GET请求中NAME的值$is_args #如果请求中有参数，值为"?"，否则为空字符串$uri #请求中的当前URI(不带请求参数，参数位于$args)，可以不同于浏览器传递的$request_uri的值，它可以通过内部重定向，或者使用index指令进行修改，$uri不包含主机名，如"/foo/bar.html"。$document_uri #同 $uri$document_root #当前请求的文档根目录或别名$host #优先级：HTTP请求行的主机名&gt;"HOST"请求头字段&gt;符合请求的服务器名.请求中的主机头字段，如果请求中的主机头不可用，则为服务器处理请求的服务器名称$hostname #主机名$https #如果开启了SSL安全模式，值为"on"，否则为空字符串。$binary_remote_addr #客户端地址的二进制形式，固定长度为4个字节$body_bytes_sent #传输给客户端的字节数，响应头不计算在内；这个变量和Apache的mod_log_config模块中的"%B"参数保持兼容$bytes_sent #传输给客户端的字节数$connection #TCP连接的序列号$connection_requests #TCP连接当前的请求数量$content_length #"Content-Length" 请求头字段$content_type #"Content-Type" 请求头字段$cookie_name #cookie名称$limit_rate #用于设置响应的速度限制$msec #当前的Unix时间戳$nginx_version #nginx版本$pid #工作进程的PID$pipe #如果请求来自管道通信，值为"p"，否则为"."$proxy_protocol_addr #获取代理访问服务器的客户端地址，如果是直接访问，该值为空字符串$realpath_root #当前请求的文档根目录或别名的真实路径，会将所有符号连接转换为真实路径$remote_addr #客户端地址$remote_port #客户端端口$remote_user #用于HTTP基础认证服务的用户名$request #代表客户端的请求地址$request_body #客户端的请求主体：此变量可在location中使用，将请求主体通过proxy_pass，fastcgi_pass，uwsgi_pass和scgi_pass传递给下一级的代理服务器$request_body_file #将客户端请求主体保存在临时文件中。文件处理结束后，此文件需删除。如果需要之一开启此功能，需要设置client_body_in_file_only。如果将次文件传 递给后端的代理服务器，需要禁用request body，即设置proxy_pass_request_body off，fastcgi_pass_request_body off，uwsgi_pass_request_body off，or scgi_pass_request_body off$request_completion #如果请求成功，值为"OK"，如果请求未完成或者请求不是一个范围请求的最后一部分，则为空$request_filename #当前连接请求的文件路径，由root或alias指令与URI请求生成$request_length #请求的长度 (包括请求的地址，http请求头和请求主体)$request_method #HTTP请求方法，通常为"GET"或"POST"$request_time #处理客户端请求使用的时间,单位为秒，精度毫秒； 从读入客户端的第一个字节开始，直到把最后一个字符发送给客户端后进行日志写入为止。$request_uri #这个变量等于包含一些客户端请求参数的原始URI，它无法修改，请查看$uri更改或重写URI，不包含主机名，例如："/cnphp/test.php?arg=freemouse"$scheme #请求使用的Web协议，"http" 或 "https"$server_addr #服务器端地址，需要注意的是：为了避免访问linux系统内核，应将ip地址提前设置在配置文件中$server_name #服务器名$server_port #服务器端口$server_protocol #服务器的HTTP版本，通常为 "HTTP/1.0" 或 "HTTP/1.1"$status #HTTP响应代码$time_iso8601 #服务器时间的ISO 8610格式$time_local #服务器时间（LOG Format 格式）$cookie_NAME #客户端请求Header头中的cookie变量，前缀"$cookie_"加上cookie名称的变量，该变量的值即为cookie名称的值$http_NAME #匹配任意请求头字段；变量名中的后半部分NAME可以替换成任意请求头字段，如在配置文件中需要获取http请求头："Accept-Language"，$http_accept_language即可$http_cookie$http_host #请求地址，即浏览器中你输入的地址（IP或域名）$http_referer #url跳转来源,用来记录从那个页面链接访问过来的$http_user_agent #用户终端浏览器等信息$http_x_forwarded_for$sent_http_NAME #可以设置任意http响应头字段；变量名中的后半部分NAME可以替换成任意响应头字段，如需要设置响应头Content-length，$sent_http_content_length即可$sent_http_cache_control$sent_http_connection$sent_http_content_type$sent_http_keep_alive$sent_http_last_modified$sent_http_location$sent_http_transfer_encoding例：http://localhost:88/test1/test2/test.php$host：localhost$server_port：88$request_uri：http://localhost:88/test1/test2/test.php$document_uri：/test1/test2/test.php$document_root：/var/www/html$request_filename：/var/www/html/test1/test2/test.php 2.3 常用正则. ： 匹配除换行符以外的任意字符? ： 重复0次或1次+ ： 重复1次或更多次* ： 重复0次或更多次\d ：匹配数字^ ： 匹配字符串的开始$ ： 匹配字符串的介绍{n} ： 重复n次{n,} ： 重复n次或更多次[c] ： 匹配单个字符c[a-z] ： 匹配a-z小写字母的任意一个小括号()之间匹配的内容，可以在后面通过$1来引用，$2表示的是前面第二个()里的内容。正则里面容易让人困惑的是\转义特殊字符。 2.4 rewrite实例例1：12345678910111213141516171819202122232425262728293031http &#123; # 定义image日志格式 log_format imagelog '[$time_local] ' $image_file ' ' $image_type ' ' $body_bytes_sent ' ' $status; # 开启重写日志 rewrite_log on; server &#123; root /home/www; location / &#123; # 重写规则信息 error_log logs/rewrite.log notice; # 注意这里要用‘’单引号引起来，避免&#123;&#125; rewrite '^/images/([a-z]&#123;2&#125;)/([a-z0-9]&#123;5&#125;)/(.*)\.(png|jpg|gif)$' /data?file=$3.$4; # 注意不能在上面这条规则后面加上“last”参数，否则下面的set指令不会执行 set $image_file $3; set $image_type $4; &#125; location /data &#123; # 指定针对图片的日志格式，来分析图片类型和大小 access_log logs/images.log mian; root /data/images; # 应用前面定义的变量。判断首先文件在不在，不在再判断目录在不在，如果还不在就跳转到最后一个url里 try_files /$arg_file /image404.html; &#125; location = /image404.html &#123; # 图片不存在返回特定的信息 return 404 "image not found\n"; &#125;&#125; 对形如/images/ef/uh7b3/test.png的请求，重写到/data?file=test.png，于是匹配到location /data，先看/data/images/test.png文件存不存在，如果存在则正常响应，如果不存在则重写tryfiles到新的image404 location，直接返回404状态码。 例2：1rewrite ^/images/(.*)_(\d+)x(\d+)\.(png|jpg|gif)$ /resizer/$1.$4?width=$2&amp;height=$3? last; 对形如/images/bla_500x400.jpg的文件请求，重写到/resizer/bla.jpg?width=500&amp;height=400地址，并会继续尝试匹配location。 例3：见 ssl部分页面加密 。 参考 http://www.nginx.cn/216.htmlhttp://www.ttlsa.com/nginx/nginx-rewriting-rules-guide/老僧系列nginx之rewrite规则快速上手http://fantefei.blog.51cto.com/2229719/919431]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx location rewrite</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创建TLS证书和秘钥]]></title>
    <url>%2F2018%2F01%2F28%2F%E5%88%9B%E5%BB%BATLS%E8%AF%81%E4%B9%A6%E5%92%8C%E7%A7%98%E9%92%A5%2F</url>
    <content type="text"><![CDATA[创建TLS证书和秘钥kubernetes系统各组件需要使用TLS证书对通信进行加密，本文档使用CloudFlare的PKI工具集cfssl来生成Certificate Authority(CA)证书和秘钥文件，CA 是自签名的证书，用来签名后续创建的其它TLS证书。 安装 CFSSL1234# wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 -O /usr/local/bin/cfssl# wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 -O /usr/local/bin/cfssljson# wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 -O /usr/local/bin/cfssl-certinfo# chmod +x /usr/local/bin/cfssl* 创建CA(Certificate Authority)创建CA配置文件 1234567891011121314151617181920# cfssl print-defaults config &gt; ca-config.json# cat ca-config.json&#123; "signing": &#123; "default": &#123; "expiry": "87600h" &#125;, "profiles": &#123; "kubernetes": &#123; "usages": [ "signing", "key encipherment", "server auth", "client auth" ], "expiry": "87600h" &#125; &#125; &#125;&#125; 创建CA证书签名请求 12345678910111213141516171819# cfssl print-defaults csr &gt; ca-csr.json # cat ca-csr.json &#123; "CN": "kubernetes", "key": &#123; "algo": "rsa", "size": 2048 &#125;, "names": [ &#123; "C": "CN", "ST": "BeiJing", "L": "BeiJing", "O": "k8s", "OU": "System" &#125; ]&#125;# cfssl gencert -initca ca-csr.json | cfssljson -bare ca 创建kube-apiserver证书创建kube-apiserver证书签名请求 注意：默认kube-apiserver证书没有权限访问API接口, 会提示: Unauthorized 注意：如果kube-apiserver证书访问API接口, 需要设置: [“O”: “system:masters”] 注意：此处需要将dns ip(首个IP地址)、etcd、k8s-master节点的ip全部加上. 123456789101112131415161718192021222324252627282930313233343536373839# cfssl print-defaults csr &gt; kubernetes-csr.json# cat kube-apiserver-csr.json &#123; "CN": "kubernetes", "hosts": [ "127.0.0.1", "172.21.0.1", "172.16.30.171", "172.16.30.172", "172.16.30.173", "kubernetes", "kubernetes.default", "kubernetes.default.svc", "kubernetes.default.svc.cluster", "kubernetes.default.svc.cluster.local" ], "key": &#123; "algo": "rsa", "size": 2048 &#125;, "names": [ &#123; "C": "CN", "ST": "BeiJing", "L": "BeiJing", "O": "k8s", "OU": "System" &#125; ]&#125;``` 生成kubernetes证书和私钥``` bash# cfssl gencert -ca=ca.pem \ -ca-key=ca-key.pem \ -config=ca-config.json \ -profile=kubernetes kube-apiserver-csr.json | cfssljson -bare kube-apiserver 创建kube-controller-manager证书创建kube-controller-manager证书签名请求 123456789101112131415161718192021222324252627# cfssl print-defaults csr &gt; kube-controller-manager-csr.json # cat kube-controller-manager-csr.json &#123; "CN": "system:kube-controller-manager", "hosts": [], "key": &#123; "algo": "rsa", "size": 2048 &#125;, "names": [ &#123; "C": "CN", "ST": "BeiJing", "L": "BeiJing", "O": "system:kube-controller-manager", "OU": "System" &#125; ]&#125;``` 生成kube-controller-manager证书和私钥``` bash# cfssl gencert -ca=ca.pem \ -ca-key=ca-key.pem \ -config=ca-config.json \ -profile=kubernetes kube-controller-manager-csr.json | cfssljson -bare kube-controller-manager 创建kube-scheduler证书创建kube-scheduler证书签名请求 12345678910111213141516171819# cfssl print-defaults csr &gt; admin-csr.json # cat kube-scheduler-csr.json &#123; "CN": "system:kube-scheduler", "hosts": [], "key": &#123; "algo": "rsa", "size": 2048 &#125;, "names": [ &#123; "C": "CN", "ST": "BeiJing", "L": "BeiJing", "O": "system:kube-scheduler", "OU": "System" &#125; ]&#125; 生成kube-scheduler证书和私钥 1234# cfssl gencert -ca=ca.pem \ -ca-key=ca-key.pem \ -config=ca-config.json \ -profile=kubernetes kube-scheduler-csr.json | cfssljson -bare kube-scheduler 创建kubelet证书创建kubelet证书签名请求 12345678910111213141516171819# cat &gt; kubelet-csr.json &lt;&lt; EOF&#123; "CN": "kubelet", "hosts": [], "key": &#123; "algo": "rsa", "size": 2048 &#125;, "names": [ &#123; "C": "CN", "ST": "BeiJing", "L": "BeiJing", "O": "system:masters", "OU": "System" &#125; ]&#125;EOF 生成kubelet证书和私钥 1234cfssl gencert -ca=ca.pem \ -ca-key=ca-key.pem \ -config=ca-config.json \ -profile=kubernetes kubelet-csr.json | cfssljson -bare kubelet 创建kube-proxy证书创建kube-proxy证书签名请求 12345678910111213141516171819# cfssl print-defaults csr &gt; kube-proxy-csr.json# cat kube-proxy-csr.json&#123; "CN": "system:kube-proxy", "hosts": [], "key": &#123; "algo": "rsa", "size": 2048 &#125;, "names": [ &#123; "C": "CN", "ST": "BeiJing", "L": "BeiJing", "O": "system:node-proxier", "OU": "System" &#125; ]&#125; 生成kube-proxy客户端证书和私钥 1234# cfssl gencert -ca=ca.pem \ -ca-key=ca-key.pem \ -config=ca-config.json \ -profile=kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxy 证书校验校验kube-apiserver证书 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980# cfssl-certinfo -cert kube-apiserver.pem&#123; "subject": &#123; "common_name": "kubernetes", "country": "CN", "organization": "system:masters", "organizational_unit": "System", "locality": "BeiJing", "province": "BeiJing", "names": [ "CN", "BeiJing", "BeiJing", "system:masters", "System", "kubernetes" ] &#125;, "issuer": &#123; "common_name": "kubernetes", "country": "CN", "organization": "k8s", "organizational_unit": "System", "locality": "BeiJing", "province": "BeiJing", "names": [ "CN", "BeiJing", "BeiJing", "k8s", "System", "kubernetes" ] &#125;, "serial_number": "533666226632105718421042600083075622217402341392", "sans": [ "kubernetes", "kubernetes.default", "kubernetes.default.svc", "kubernetes.default.svc.cluster", "kubernetes.default.svc.cluster.local", "127.0.0.1", "172.21.0.1", "172.16.30.171", "172.16.30.172", "172.16.30.173" ], "not_before": "2017-07-31T08:57:00Z", "not_after": "2018-07-31T08:57:00Z", "sigalg": "SHA256WithRSA", "authority_key_id": "6B:68:CF:57:62:6B:60:7E:F3:2C:AC:1A:20:6F:27:6A:EA:84:98:A8", "subject_key_id": "3C:6C:67:14:69:F8:42:2A:5C:3C:28:65:B6:A3:95:80:49:A6:6:C", "pem": "-----BEGIN CERTIFICATE-----MIIEkDCCA3igAwIBAgIUEdNzDqRQMswGL4KikzjnizkfBS4wDQYJKoZIhvcNAQELBQAwZTELMAkGA1UEBhMCQ04xEDAOBgNVBAgTB0JlaUppbmcxEDAOBgNVBAcTB0JlaUppbmcxDDAKBgNVBAoTA2s4czEPMA0GA1UECxMGU3lzdGVtMRMwEQYDVQQDEwprdWJlcm5ldGVzMB4XDTE3MDcyNzA5MjcwMFoXDTE4MDcyNzA5MjcwMFowcDELMAkGA1UEBhMCQ04xEDAOBgNVBAgTB0JlaUppbmcxEDAOBgNVBAcTB0JlaUppbmcxFzAVBgNVBAoTDnN5c3RlbTptYXN0ZXJzMQ8wDQYDVQQLEwZTeXN0ZW0xEzARBgNVBAMTCmt1YmVybmV0ZXMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQClXFE1qVQ9HiHDEbyfDMqsrO8p0Rn02ta+xWAbmJhwgNstFfuW0Lz9XmtpclDRfF2U5QOJX7TrTZz2xhjRxXzUb/4EU035VH273tb+3+orUbggMcUzavpbm0zFqqSeSTxIoWhwwiIUG33BR7i6kvyH7eHraq/vYn8NbG2t8ufoJFgPys6zjC9rDWqNlBXume69n8BDHTfDQUgUVLZDDZyef+KwvtziHUtEgEakaI9MgDV3CdkMAvXrnIeiMHQzRBen3glizk4i+OCWd9oI7cB7oqvXUm+pTEAzOPQaGkkq7A2R8UHTFgOyAkw8saKwRvBacWhmBDa/+CVYKfiNBzDRAgMBAAGjggErMIIBJzAOBgNVHQ8BAf8EBAMCBaAwHQYDVR0lBBYwFAYIKwYBBQUHAwEGCCsGAQUFBwMCMAwGA1UdEwEB/wQCMAAwHQYDVR0OBBYEFHfVB5vi0gEh2rGjBzWVr9+2Jrs9MB8GA1UdIwQYMBaAFGHhP32/2ThF4VlOuaKjiKbG/CMcMIGnBgNVHREEgZ8wgZyCCmt1YmVybmV0ZXOCEmt1YmVybmV0ZXMuZGVmYXVsdIIWa3ViZXJuZXRlcy5kZWZhdWx0LnN2Y4Iea3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVygiRrdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWyHBH8AAAGHBAr+AAGHBMCoA1+HBMCoA2CHBMCoA2MwDQYJKoZIhvcNAQELBQADggEBABlTNX+MVTfViozPrwH6QkXfbHTH9kpsm9SPZhpzjON4pAcY5kP3t6DInX9DSdivyuVn3jJz6BaBIoUh5RJRsq6ArMpbl1g7dyZnHZXPjLtMAFYGgnBjH6XVEQ1fFZbSZjvbti/l7SH7f9aqtywzqNCDqmwx+2gNoWwd11y0A7zxMVK28l6apbMfcVHLrHLKikoV+sLmvKCLdh7/qrTToono0j5nMzuQWfNU3UsNHOZZ1uNUQsuurv95LUWG5t3PKpRoi0Z5kePBdLoD1CHqS1DEPkZt+sj6e6vqQSBAM8usNEUwi7ASOY2zAaMGaDz1i4/WZhJSUQyDfx7HzJpAmBE=-----END CERTIFICATE-----"&#125; 分发证书将TLS证书拷贝到Kubernetes Master和Kubernetes node的配置目录 1# mkdir -p /etc/kubernetes/ssl &amp;&amp; cp /tmp/ssl/*.pem /etc/kubernetes/ssl]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建flannel服务]]></title>
    <url>%2F2018%2F01%2F28%2F%E6%90%AD%E5%BB%BAflannel%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[搭建Flannel服务什么是Flannel？Flannel是CoreOS团队针对Kubernetes设计的一个覆盖网络(Overlay Network)工具，其目的在于帮助每一个使用Kuberentes的CoreOS主机拥有一个完整的子网。 Flannel工作原理flannel为全部的容器使用一个network，然后在每个host上从network中划分一个子网subnet。host上的容器创建网络时，从subnet中划分一个ip给容器。flannel不存在所谓的控制节点，而是每个host上的flanneld从一个etcd中获取相关数据，然后声明自己的子网网段，并记录在etcd中。如果有host对数据转发时，从etcd中查询到该子网所在的host的ip，然后将数据发往对应host上的flanneld，交由其进行转发。 Flannel架构介绍 创建Pod Network注意：flanneld v0.9.0版本目前不支持etcd v3, 使用etcd v2 API写入配置key和网段数据 注意：集群网段地址172.20.0.0/16, SVC(DNS)网段地址172.21.0.0/16 1# etcdctl set /flannel/network/config '&#123; "Network": "172.20.0.0/16", "Backend": &#123; "Type": "host-gw" &#125; &#125;' 安装flannel服务123456789101112131415# yum -y install flannel# vim /etc/sysconfig/flanneld# Flanneld configuration options # etcd url location. Point this to the server where etcd runsFLANNEL_ETCD_ENDPOINTS="http://172.16.30.171:2379,http://172.16.30.172:2379,http://172.16.30.173:2379" # etcd config key. This is the configuration key that flannel queries# For address range assignmentFLANNEL_ETCD_PREFIX="/flannel/network" # Any additional options that you want to passFLANNEL_OPTIONS="-iface=eth0 -ip-masq"# systemctl enable flanneld &amp;&amp; systemctl restart flanneld &amp;&amp; systemctl status flanneld 配置docker启动服务注意：flannel服务要优先启动，docker服务启动脚本没有配置flannel服务优先级。 123456789101112131415161718192021222324252627282930313233343536373839404142# vim/usr/lib/systemd/system/docker.service[Unit]Description=Docker Application Container EngineDocumentation=http://docs.docker.comAfter=network.targetAfter=flanneld.serviceWants=docker-storage-setup.serviceRequires=docker-cleanup.timer[Service]Type=notifyNotifyAccess=allKillMode=processEnvironmentFile=-/etc/sysconfig/dockerEnvironmentFile=-/etc/sysconfig/docker-storageEnvironmentFile=-/etc/sysconfig/docker-networkEnvironment=GOTRACEBACK=crashEnvironment=DOCKER_HTTP_HOST_COMPAT=1Environment=PATH=/usr/libexec/docker:/usr/bin:/usr/sbinExecStart=/usr/bin/dockerd-current \ --add-runtime docker-runc=/usr/libexec/docker/docker-runc-current \ --default-runtime=docker-runc \ --exec-opt native.cgroupdriver=systemd \ --userland-proxy-path=/usr/libexec/docker/docker-proxy-current \ $OPTIONS \ $DOCKER_STORAGE_OPTIONS \ $DOCKER_NETWORK_OPTIONS \ $ADD_REGISTRY \ $BLOCK_REGISTRY \ $INSECURE_REGISTRYExecReload=/bin/kill -s HUP $MAINPIDLimitNOFILE=1048576LimitNPROC=1048576LimitCORE=infinityTimeoutStartSec=0Restart=on-abnormalMountFlags=slave[Install]WantedBy=multi-user.target# systemctl enable docker &amp;&amp; systemctl restart docker &amp;&amp; systemctl status docker 验证docker服务获取IP是否正常注意：yum方式安装flannel，docker无需做任何配置的；如果docker服务没有正确获取IP，请检查flannel服务是否正常启动。 12345678# ifconfig docker0docker0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.16.36.1 netmask 255.255.255.0 broadcast 0.0.0.0 ether 02:42:d0:0b:23:be txqueuelen 0 (Ethernet) RX packets 39657261 bytes 7409081483 (6.9 GiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 40524935 bytes 23758435104 (22.1 GiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo 安装简介]]></title>
    <url>%2F2018%2F01%2F28%2Fhexo%E5%AE%89%E8%A3%85%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[搭建etcd集群服务]]></title>
    <url>%2F2018%2F01%2F28%2F%E6%90%AD%E5%BB%BAetcd%E9%9B%86%E7%BE%A4%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[搭建etcd集群服务Etcd服务应用场景要问etcd是什么？很多人第一反应可能是一个键值存储仓库，却没有重视官方定义的后半句，用于配置共享和服务发现。etcd作为一个受到ZooKeeper与doozer启发而催生的项目，除了拥有与之类似的功能外，更专注于以下四点: 简单：基于HTTP+JSON的API让你用curl就可以轻松使用。 安全：可选SSL客户认证机制。 快速：每个实例每秒支持一千次写操作。 可信：使用Raft算法充分实现了分布式。 分布式系统中的数据分为控制数据和应用数据。etcd的使用场景默认处理的数据都是控制数据，对于应用数据，只推荐数据量很小，但是更新访问频繁的情况。应用场景有如下几类: 场景一：服务发现（Service Discovery） 场景二：消息发布与订阅 场景三：负载均衡 场景四：分布式通知与协调 场景五：分布式锁、分布式队列 场景六：集群监控与Leader竞选 举个最简单的例子，如果你需要一个分布式存储仓库来存储配置信息，并且希望这个仓库读写速度快、支持高可用、部署简单、支持http接口，那么就可以使用etcd。 安装配置etcd服务1234567891011121314# yum -y install etcd# cp /etc/etcd/etcd.conf /etc/etcd/etcd.conf.bak_$(date +%Y%m%d)# vim /etc/etcd/etcd.confETCD_NAME=etcd_node1 // 节点名称ETCD_DATA_DIR="/var/lib/etcd/default.etcd"ETCD_LISTEN_PEER_URLS="http://172.16.30.171:2380"ETCD_LISTEN_CLIENT_URLS="http://172.16.30.171:2379,http://127.0.0.1:2379" // 必须增加127.0.0.1否则启动会报错ETCD_INITIAL_ADVERTISE_PEER_URLS="http://172.16.30.171:2380"ETCD_INITIAL_CLUSTER="etcd_node1=http://172.16.30.171:2380,etcd_node2=http://172.16.30.172:2380,etcd_node3=http://172.16.30.173:2380" // 集群IP地址ETCD_INITIAL_CLUSTER_STATE="new" // 初始化集群,第二次启动时将状态改为: "existing"ETCD_INITIAL_CLUSTER_TOKEN="etcd-cluster"ETCD_ADVERTISE_CLIENT_URLS="http://172.16.30.171:2379"# systemctl enable etcd.service # systemctl start etcd.service &amp;&amp; systemctl status etcd.service 设置API版本 默认版本：v2 [根据实际情况设定] 12# echo 'export ETCDCTL_API=3' &gt;&gt; /etc/profile# . /etc/profile 查看和验证etcd集群服务状态查看etcd集群成员 1234# etcdctl member list7e218077496bccf9: name=etcd_node1 peerURLs=http://172.16.30.171:2380 clientURLs=http://172.16.30.171:2379 isLeader=true92f1b7c038a4300a: name=etcd_node2 peerURLs=http://172.16.30.172:2380 clientURLs=http://172.16.30.172:2379 isLeader=falsec8611e11b142e510: name=etcd_node3 peerURLs=http://172.16.30.173:2380 clientURLs=http://172.16.30.173:2379 isLeader=false 验证etcd集群状态 12345# etcdctl cluster-healthmember 7e218077496bccf9 is healthy: got healthy result from http://172.16.30.171:2379member 92f1b7c038a4300a is healthy: got healthy result from http://172.16.30.172:2379member c8611e11b142e510 is healthy: got healthy result from http://172.16.30.173:2379cluster is healthy //表示安装成功 etcd集群增加节点将目标节点添加到etcd集群 123456# etcdctl member add etcd_node4 http://172.16.30.174:2380Added member named etcd_etcd4 with ID 5282b16e923af92f to cluster ETCD_NAME="etcd_node4"ETCD_INITIAL_CLUSTER="etcd_node4=http://172.16.30.174:2380,etcd_node1=http://172.16.30.171:2380,etcd_node2=http://172.16.30.172:2380,etcd_node3=http://172.16.30.173:2380"ETCD_INITIAL_CLUSTER_STATE="existing" 查看成员列表. etcd_node4节点状态为: unstarted 12345# etcdctl member list5282b16e923af92f[unstarted]: peerURLs=http://172.16.30.174:23807e218077496bccf9: name=etcd_node1 peerURLs=http://172.16.30.171:2380 clientURLs=http://172.16.30.171:2379 isLeader=true92f1b7c038a4300a: name=etcd_node2 peerURLs=http://172.16.30.172:2380 clientURLs=http://172.16.30.172:2379 isLeader=falsec8611e11b142e510: name=etcd_node3 peerURLs=http://172.16.30.173:2380 clientURLs=http://172.16.30.173:2379 isLeader=false 配置etcd_node4节点的etcd.conf文件 123456789101112# vim /etc/etcd/etcd.confETCD_NAME="etcd_node4" // 节点名称,对应etcd添加节点命令时输出的信息ETCD_DATA_DIR="/var/lib/etcd/etcd_node4.etcd"ETCD_LISTEN_PEER_URLS="http://172.16.30.174:2380"ETCD_LISTEN_CLIENT_URLS="http://172.16.30.174:2379,http://127.0.0.1:2379"ETCD_INITIAL_ADVERTISE_PEER_URLS="http://172.16.30.174:2380"ETCD_INITIAL_CLUSTER="etcd_node4=http://172.16.30.174:2380,etcd_node1=http://172.16.30.171:2380,etcd_node2=http://172.16.30.171:2380,etcd_node3=http://172.16.30.173:2380" // 集群列表,对应etcd添加节点命令时输出的信息ETCD_INITIAL_CLUSTER_STATE="existing" // 集群状态,对应etcd添加节点命令时输出的信息ETCD_INITIAL_CLUSTER_TOKEN="etcd-cluster"ETCD_ADVERTISE_CLIENT_URLS="http://172.16.30.174:2379"# systemctl enable etcd.service # systemctl start etcd.service &amp;&amp; systemctl status etcd.service 再次查看成员列表. etcd_etcd4节点状态已经显示正常 12345# etcdctl member list5282b16e923af92f: name=etcd_node4 peerURLs=http://172.16.30.174:2380 clientURLs=http://172.16.30.174:2379 isLeader=false7e218077496bccf9: name=etcd_node1 peerURLs=http://172.16.30.171:2380 clientURLs=http://172.16.30.171:2379 isLeader=true92f1b7c038a4300a: name=etcd_node2 peerURLs=http://172.16.30.172:2380 clientURLs=http://172.16.30.172:2379 isLeader=falsec8611e11b142e510: name=etcd_node3 peerURLs=http://172.16.30.173:2380 clientURLs=http://172.16.30.173:2379 isLeader=false etcd集群删除节点删除etcd_etcd4节点 123456# etcdctl member remove 5282b16e923af92fRemoved member 5282b16e923af92f from cluster# etcdctl member list7e218077496bccf9: name=etcd_node1 peerURLs=http://172.16.30.171:2380 clientURLs=http://172.16.30.171:2379 isLeader=true92f1b7c038a4300a: name=etcd_node2 peerURLs=http://172.16.30.172:2380 clientURLs=http://172.16.30.172:2379 isLeader=falsec8611e11b142e510: name=etcd_node3 peerURLs=http://172.16.30.173:2380 clientURLs=http://172.16.30.173:2379 isLeader=false]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建Alertmanager服务]]></title>
    <url>%2F2018%2F01%2F28%2F%E6%90%AD%E5%BB%BAAlertmanager%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[搭建Alertmanager服务什么是Alertmanager?Alertmanager主要处理由类似Prometheus服务器等客户端发来的警报，之后需要删除重复、分组，并将它们通过路由发送到正确的接收器，比如电子邮件、Slack等。 Alertmanager与Prometheus是相互分离的两个部分。Prometheus服务器根据报警规则将警报发送给Alertmanager，然后Alertmanager将silencing、inhibition、aggregation等消息通过电子邮件、PaperDuty和HipChat发送通知。 下载Alertmanager文件注意：本示例用的Alertmanager yaml文件均是在本地测试环境使用的，请自行修改配置文件。1234# mkdir alertmanger &amp;&amp; cd alertmanger# wget https://raw.githubusercontent.com/Donyintao/Prometheus/master/alertmanager-deployment.yaml# wget https://raw.githubusercontent.com/Donyintao/Prometheus/master/alertmanager-configmap.yaml# wget https://raw.githubusercontent.com/Donyintao/Prometheus/master/alertmanager-ingress.yaml 安装Alertmanager服务12345678910111213# kubectl apply -f .configmap "alertmanager" createddeployment "alertmanager" createdservice "alertmanager" createdingress "alertmanager" created# kubectl get pod -n monitoringNAME READY STATUS RESTARTS AGEalertmanager-1688473584-hzd51 1/1 Running 0 9d# kubectl get ingress -n monitoring NAME HOSTS ADDRESS PORTS AGEalertmanager alert.host.com 192.168.3.99 80 9d 验证Alertmanager服务这时通过浏览器访问http://alert.host.com来访问Alertmanager的界面，查看的页面查看FILTER是空的，这是因为Prometheus还没有和Alertmanager建立联系。 Prometheus rules配置设置警报和通知的主要步骤流程(其实就简单三步，但是写的话，总感觉很复杂的样子)： 安装配置Alertmanager 在Prometheus中创建告警规则 配置Prometheus通过-alertmanager.url标志与Alertmanager通信 使用ConfigMap方式，创建Prometheus rules文件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# vim prometheus-rules-configmap.yamlapiVersion: v1kind: ConfigMapmetadata: creationTimestamp: null name: prometheus-rules namespace: monitoringdata: prometheus.rules: | ALERT Container_Memory_RSS IF ((sum(container_memory_rss&#123;job="kubernetes-cadvisor",pod_name!=""&#125;) by (pod_name)) /(sum(container_spec_memory_limit_bytes&#123;job="kubernetes-cadvisor",pod_name!=""&#125;) by (pod_name)) * 100) &gt; 95 FOR 1m LABELS &#123; severity = "剩余内存: &#123;&#123; $value &#125;&#125;" &#125; ANNOTATIONS &#123; summary = "检测内存使用率过高.", description = "使用内存高于 95%. 使用内存: &#123;&#123; $value &#125;&#125;" &#125; ALERT Container_Network_RX_Average IF ((sum (rate (container_network_receive_bytes_total&#123;job="kubernetes-nodes",pod_name!=""&#125;[1m])) by (pod_name)) / 1024) &gt; 102400 FOR 1m LABELS &#123; severity = "RX带宽使用率: &#123;&#123; $value &#125;&#125;" &#125; ANNOTATIONS &#123; summary = "检测网络带宽使用率过高.", description = "网络带宽使用高于 100M. RX带宽使用率: &#123;&#123; $value &#125;&#125;" &#125; ALERT Container_Network_TX_Average IF ((sum (rate (container_network_transmit_bytes_total&#123;job="kubernetes-nodes",pod_name!=""&#125;[1m])) by (pod_name)) / 1024) &gt; 102400 FOR 1m LABELS &#123; severity = "TX带宽使用率: &#123;&#123; $value &#125;&#125;" &#125; ANNOTATIONS &#123; summary = "检测网络带宽使用率过高.", description = "网络带宽使用高于 100M. TX带宽使用率: &#123;&#123; $value &#125;&#125;" &#125; ALERT Container_USAGE_CPU_Average IF ((sum(rate(container_cpu_usage_seconds_total&#123;job="kubernetes-nodes",image!="",pod_name!=""&#125;[1m])) BY (pod_name)) * 100) &gt; 95 FOR 1m FOR 1m LABELS &#123; severity = "CPU使用率: &#123;&#123; $value &#125;&#125;" &#125; ANNOTATIONS &#123; summary = "检测CPU使用率过高.", description = "CPU使用高于 95%. CPU使用率: &#123;&#123; $value &#125;&#125;" &#125; # kubectl apply -f prometheus-rules-configmap.yaml configmap "prometheus-rules" created 修改prometheus-configmap.yaml文件，在global配置下增加两行内容： 12rule_files: - '/etc/prometheus-rules/*.rules' 修改prometheus-deployment.yaml文件，在containers.args配置下增加Alertmanager url地址，用于发送报警规则。 123containers: args: - '-alertmanager.url=http://alertmanager' 修改prometheus-deployment.yaml文件，在containers配置下增加rules-volume挂载，用于存储报警规则文件。 123456containers: - name: rules-volume mountPath: /etc/prometheus-rules- name: rules-volume configMap: name: prometheus-rules 重新加载Prometheus服务1234# kubectl apply -f prometheus-configmap.yaml -f prometheus-deployment.yaml configmap "prometheus" configured deployment "prometheus" configuredservice "prometheus" configured 验证Prometheus报警规则这时通过浏览器访问http://prometheus.host.com来访问Alert的界面，会发现已经有新生成的报警规则；绿色表示：正常，红色表示：异常。 再次通过浏览器访问http://alert.host.com来访问Alertmanager的界面，查看的页面查看FILTER已经有数据了，这是因为Prometheus已经和Alertmanager建立联系。]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建Docker-Registry]]></title>
    <url>%2F2018%2F01%2F28%2F%E6%90%AD%E5%BB%BADocker-Registry%2F</url>
    <content type="text"><![CDATA[搭建Docker私有仓库为什么要使用Docker私有仓库？使用私有仓库有许多优点： 节省网络带宽，针对于每个镜像不用每个人都去中央仓库上面去下载，只需要从私有仓库中下载即可； 提供镜像资源利用，针对于公司内部使用的镜像，推送到本地的私有仓库中，以供公司内部相关人员使用。 安装Docker Registry推荐使用Docker-compose管理工具： Docker-compose是一个非常有用的Docker运行，管理的工具。 可以通过定义compose文件，使用简单的一条命令同时起多个Docker Container运行不同的服务。 Docker-compose对于开发，测试，环境保存以及CI都提供了非常大的便利。 安装Docker-compose管理工具注意：使用pip安装的docker-compose可能在执行时还会报代码有bug；推荐直接从github中下载稳定的release版本安装。12# curl -L https://github.com/docker/compose/releases/download/1.16.0/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose# chmod +x /usr/local/bin/docker-compose 配置Registry Container和Registry UI创建docker-registry目录 12# mkdir -p /usr/local/docker-registry &amp;&amp; cd /usr/local/docker-registry# mdkir -p ./registry/&#123;data,conf&#125; 创建配置文件config-ui.yml 1234567# vim ./registry/conf/config-ui.ymlregistry: url: http://192.168.100.115:5000/v2/ name: registry.host.com readonly: false auth: enabled: false 创建配置文件config-srv.yml 123456789101112131415161718# vim ./registry/conf/config-ui.ymlversion: 0.1storage: filesystem: rootdirectory: /var/lib/registry delete: enabled: truehttp: addr: 0.0.0.0:5000log: level: info``` ## 配置Nginx反向代理创建`Nginx`配置目录``` bash# mkdir ./nginx/conf 创建配置文件registry.conf 1234567891011121314151617181920212223242526272829303132333435363738394041424344vim ./nginx/conf/registry.confupstream docker-registry &#123; server 192.168.100.115:5000;&#125;upstream docker-registry-ui &#123; server 192.168.100.115:8080;&#125;server &#123; listen 80; listen 443 ssl; server_name registry.host.com; # SSL ssl_certificate /etc/nginx/conf.d/server.pem; ssl_certificate_key /etc/nginx/conf.d/server-key.pem; client_max_body_size 0; chunked_transfer_encoding on; location / &#123; proxy_pass http://docker-registry-ui; proxy_set_header Host $http_host; # required for docker client's sake proxy_set_header X-Real-IP $remote_addr; # pass on real client's IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_read_timeout 900; &#125; location /v2/ &#123; if ($http_user_agent ~ "^(docker\/1\.(3|4|5(?!\.[0-9]-dev))|Go ).*$" ) &#123; return 404; &#125; proxy_pass http://docker-registry; proxy_set_header Host $http_host; # required for docker client's sake proxy_set_header X-Real-IP $remote_addr; # pass on real client's IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_read_timeout 900; &#125;&#125; 创建Docker-compose配置文件docker-compose.yml 12345678910111213141516171819202122232425# vim docker-compose.ymlnginx: image: nginx:1.10 ports: - 192.168.100.115:80:80 - 192.168.100.115:443:443 links: - registry:registry volumes: - ./nginx/conf:/etc/nginx/conf.dregistry: image: registry:2.6 ports: - 192.168.100.115:5000:5000 environment: REGISTRY_STORAGE_FILESYSTEM_ROOTDIRECTORY: /data volumes: - ./registry/data:/data - ./registry/conf/config-srv.yml:/etc/docker/registry/config.yml:roregistry-ui: image: hyper/docker-registry-web ports: - 192.168.100.115:8080:8080 volumes: - ./registry/conf/config-ui.yml:/conf/config.yml:ro 创建Nginx服务使用的TLS证书创建CA(Certificate Authority) 123456789101112131415161718192021# mkdir -p /tmp/ssl &amp;&amp; cd /tmp/ssl# cfssl print-defaults config &gt; ca-config.json# cat ca-config.json&#123; "signing": &#123; "default": &#123; "expiry": "87600h" &#125;, "profiles": &#123; "kubernetes": &#123; "usages": [ "signing", "key encipherment", "server auth", "client auth" ], "expiry": "87600h" &#125; &#125; &#125;&#125; 创建CA证书签名请求 123456789101112131415161718# cfssl print-defaults csr &gt; ca-csr.json # cat ca-csr.json &#123; "CN": "kubernetes", "key": &#123; "algo": "rsa", "size": 2048 &#125;, "names": [ &#123; "C": "CN", "ST": "BeiJing", "L": "BeiJing", "O": "k8s", "OU": "System" &#125; ]&#125; 生成CA证书和私钥 1# cfssl gencert -initca ca-csr.json | cfssljson -bare ca 创建docker-registry证书签名请求 1234567891011121314151617181920212223cat &gt; docker-registry-csr.json &lt;&lt;EOF&#123; "CN": "docker", "hosts": [ "127.0.0.1", "192.168.100.115", "registry.host.com", ], "key": &#123; "algo": "rsa", "size": 2048 &#125;, "names": [ &#123; "C": "CN", "ST": "BeiJing", "L": "BeiJing", "O": "k8s", "OU": "System" &#125; ]&#125;EOF 生成docker-registry证书和私钥 1234cfssl gencert -ca=ca.pem \ -ca-key=ca-key.pem \ -config=ca-config.json \ -profile=kubernetes docker-registry-csr.json | cfssljson -bare server 分发证书将TLS证书拷贝到Nginx的配置目录1# cp -r /tmp/ssl/server*.pem /usr/local/docker-registry/nginx/conf 运行Registry Container并使用Nginx做代理1234567# docker-compose up -d Starting docker_registry-ui_1 ... Starting docker_registry_1 ... Starting docker_registry_1Starting docker_registry_1 ... doneStarting docker_nginx_1 ... Starting docker_nginx_1 ... done 验证Registry Container服务是否正常启动注意：确定docker容器都正常运行后，用curl命令验证功能是否正常运行。使得IP:5000和IP:443访问registry都应该返回{}。 1234# curl https://192.168.100.115:443/v2/ -k&#123;&#125;# curl http://192.168.100.115:5000/v2/ -k &#123;&#125; 这时我们用浏览器访问http://registry.host.com来访问Web Registry的界面会显示正常；如果出现异常，请检查网络和防火墙配置。]]></content>
      <categories>
        <category>kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx优化之nopush,sendfile,https,keepalive等]]></title>
    <url>%2F2017%2F11%2F18%2Fnginx-001%2F</url>
    <content type="text"><![CDATA[一、nginx之tcp_nopush、tcp_nodelay、sendfile1、TCP_NODELAY你怎么可以强制 socket 在它的缓冲区里发送数据？一个解决方案是 TCP 堆栈的 TCP_NODELAY选项。这样就可以使缓冲区中的数据立即发送出去。 Nginx的 TCP_NODELAY 选项使得在打开一个新的 socket 时增加了TCP_NODELAY选项。但这时会造成一种情况：终端应用程序每产生一次操作就会发送一个包，而典型情况下一个包会拥有一个字节的数据以及40个字节长的包头，于是产生4000%的过载，很轻易地就能令网络发生拥塞。为了避免这种情况，TCP堆栈实现了等待数据 0.2秒钟，因此操作后它不会发送一个数据包，而是将这段时间内的数据打成一个大的包。这一机制是由Nagle算法保证。 Nagle化后来成了一种标准并且立即在因特网上得以实现。它现在已经成为默认配置了，但有些场合下把这一选项关掉也是合乎需要的。现在假设某个应用程序发出了一个请求，希望发送小块数据。我们可以选择立即发送数据或者等待产生更多的数据然后再一次发送两种策略。如果我们马上发送数据，那么交互性的以及客户/服务器型的应用程序将极大地受益。如果请求立即发出那么响应时间也会快一些。以上操作可以通过设置套接字的 TCP_NODELAY = on 选项来完成，这样就禁用了Nagle 算法。（不需要等待0.2s） 2、TCP_NOPUSH在 nginx 中，tcp_nopush 配置和 tcp_nodelay “互斥”。它可以配置一次发送数据的包大小。也就是说，它不是按时间累计 0.2 秒后发送包，而是当包累计到一定大小后就发送。 注：在 nginx 中，tcp_nopush 必须和 sendfile 搭配使用。 3、sendfile现在流行的web 服务器里面都提供 sendfile选项用来提高服务器性能，那到底 sendfile是什么，怎么影响性能的呢？sendfile实际上是 Linux2.0+以后的推出的一个系统调用，web服务器可以通过调整自身的配置来决定是否利用 sendfile这个系统调用。先来看一下不用 sendfile的传统网络传输过程：read(file,tmp_buf, len);write(socket,tmp_buf, len); 硬盘 &gt;&gt; kernel buffer &gt;&gt; user buffer&gt;&gt; kernel socket buffer &gt;&gt;协议栈 1）一般来说一个网络应用是通过读硬盘数据，然后写数据到socket 来完成网络传输的。上面2行用代码解释了这一点，不过上面2行简单的代码掩盖了底层的很多操作。来看看底层是怎么执行上面2行代码的： 系统调用 read()产生一个上下文切换：从 user mode 切换到 kernel mode，然后 DMA 执行拷贝，把文件数据从硬盘读到一个 kernel buffer 里。 数据从 kernel buffer拷贝到 user buffer，然后系统调用 read() 返回，这时又产生一个上下文切换：从kernel mode 切换到 user mode。 系统调用write()产生一个上下文切换：从 user mode切换到 kernel mode，然后把步骤2读到 user buffer的数据拷贝到 kernel buffer（数据第2次拷贝到 kernel buffer），不过这次是个不同的 kernel buffer，这个 buffer和 socket相关联。 系统调用 write()返回，产生一个上下文切换：从 kernel mode 切换到 user mode（第4次切换了），然后 DMA 从 kernel buffer拷贝数据到协议栈（第4次拷贝了）。 上面4个步骤有4次上下文切换，有4次拷贝，我们发现如果能减少切换次数和拷贝次数将会有效提升性能。在kernel2.0+ 版本中，系统调用 sendfile() 就是用来简化上面步骤提升性能的。sendfile() 不但能减少切换次数而且还能减少拷贝次数。 2）再来看一下用 sendfile()来进行网络传输的过程：sendfile(socket,file, len); 硬盘 &gt;&gt; kernel buffer (快速拷贝到kernelsocket buffer) &gt;&gt;协议栈 系统调用sendfile()通过 DMA把硬盘数据拷贝到 kernel buffer，然后数据被 kernel直接拷贝到另外一个与 socket相关的 kernel buffer。这里没有 user mode和 kernel mode之间的切换，在 kernel中直接完成了从一个 buffer到另一个 buffer的拷贝。 DMA 把数据从 kernelbuffer 直接拷贝给协议栈，没有切换，也不需要数据从 user mode 拷贝到 kernel mode，因为数据就在 kernel 里。 步骤减少了，切换减少了，拷贝减少了，自然性能就提升了。这就是为什么说在Nginx 配置文件里打开 sendfile on 选项能提高 web server性能的原因。 综上，这三个参数都应该配置成on：sendfile on; tcp_nopush on; tcp_nodelay on; 二、nginx长连接——keepalive当使用nginx作为反向代理时，为了支持长连接，需要做到两点： 从client到nginx的连接是长连接 从nginx到server的连接是长连接 1、保持和client的长连接： 默认情况下，nginx已经自动开启了对client连接的keep alive支持（同时client发送的HTTP请求要求keep alive）。一般场景可以直接使用，但是对于一些比较特殊的场景，还是有必要调整个别参数（keepalive_timeout和keepalive_requests）。 1234http &#123; keepalive_timeout 120s 120s; keepalive_requests 10000;&#125; 1）keepalive_timeout语法: keepalive_timeout timeout [header_timeout]; 第一个参数：设置keep-alive客户端连接在服务器端保持开启的超时值（默认75s）；值为0会禁用keep-alive客户端连接； 第二个参数：可选、在响应的header域中设置一个值“Keep-Alive: timeout=time”；通常可以不用设置； 注：keepalive_timeout默认75s，一般情况下也够用，对于一些请求比较大的内部服务器通讯的场景，适当加大为120s或者300s； 2）keepalive_requests：keepalive_requests指令用于设置一个keep-alive连接上可以服务的请求的最大数量，当最大请求数量达到时，连接被关闭。默认是100。这个参数的真实含义，是指一个keep alive建立之后，nginx就会为这个连接设置一个计数器，记录这个keep alive的长连接上已经接收并处理的客户端请求的数量。如果达到这个参数设置的最大值时，则nginx会强行关闭这个长连接，逼迫客户端不得不重新建立新的长连接。大多数情况下当QPS(每秒请求数)不是很高时，默认值100凑合够用。但是，对于一些QPS比较高（比如超过10000QPS，甚至达到30000,50000甚至更高) 的场景，默认的100就显得太低。简单计算一下，QPS=10000时，客户端每秒发送10000个请求(通常建立有多个长连接)，每个连接只能最多跑100次请求，意味着平均每秒钟就会有100个长连接因此被nginx关闭。同样意味着为了保持QPS，客户端不得不每秒中重新新建100个连接。因此，就会发现有大量的TIME_WAIT的socket连接(即使此时keep alive已经在client和nginx之间生效)。因此对于QPS较高的场景，非常有必要加大这个参数，以避免出现大量连接被生成再抛弃的情况，减少TIME_WAIT。 2、保持和server的长连接：为了让nginx和后端server（nginx称为upstream）之间保持长连接，典型设置如下：（默认nginx访问后端都是用的短连接(HTTP1.0)，一个请求来了，Nginx 新开一个端口和后端建立连接，后端执行完毕后主动关闭该链接） 123456789101112131415161718192021http &#123; upstream BACKEND &#123; server 192.168.0.1：8080 weight=1 max_fails=2 fail_timeout=30s; server 192.168.0.2：8080 weight=1 max_fails=2 fail_timeout=30s; keepalive 300; // 这个很重要！ &#125;server &#123; listen 8080 default_server; server_name &quot;&quot;; location / &#123; proxy_pass http://BACKEND; proxy_set_header Host $Host; proxy_set_header x-forwarded-for $remote_addr; proxy_set_header X-Real-IP $remote_addr; add_header Cache-Control no-store; add_header Pragma no-cache; proxy_http_version 1.1; // 这两个最好也设置 proxy_set_header Connection &quot;&quot;; &#125; &#125;&#125; 1）location中有两个参数需要设置： 12345678http &#123; server &#123; location / &#123; proxy_http_version 1.1; // 这两个最好也设置 proxy_set_header Connection &quot;&quot;; &#125; &#125;&#125; HTTP协议中对长连接的支持是从1.1版本之后才有的，因此最好通过proxy_http_version指令设置为”1.1”； 而”Connection” header应该被清理。清理的意思，我的理解，是清理从client过来的http header，因为即使是client和nginx之间是短连接，nginx和upstream之间也是可以开启长连接的。这种情况下必须清理来自client请求中的”Connection” header。 2）upstream中的keepalive设置：此处keepalive的含义不是开启、关闭长连接的开关；也不是用来设置超时的timeout；更不是设置长连接池最大连接数。官方解释： The connections parameter sets the maximum number of idle keepalive connections to upstream servers connections（设置到upstream服务器的空闲keepalive连接的最大数量） When this number is exceeded, the least recently used connections are closed. （当这个数量被突破时，最近使用最少的连接将被关闭） It should be particularly noted that the keepalive directive does not limit the total number of connections to upstream servers that an nginx worker process can open.（特别提醒：keepalive指令不会限制一个nginx worker进程到upstream服务器连接的总数量） 我们先假设一个场景： 有一个HTTP服务，作为upstream服务器接收请求，响应时间为100毫秒。如果要达到10000 QPS的性能，就需要在nginx和upstream服务器之间建立大约1000条HTTP连接。nginx为此建立连接池，然后请求过来时为每个请求分配一个连接，请求结束时回收连接放入连接池中，连接的状态也就更改为idle。我们再假设这个upstream服务器的keepalive参数设置比较小，比如常见的10. A、假设请求和响应是均匀而平稳的，那么这1000条连接应该都是一放回连接池就立即被后续请求申请使用，线程池中的idle线程会非常的少，趋进于零，不会造成连接数量反复震荡。 B、显示中请求和响应不可能平稳，我们以10毫秒为一个单位，来看连接的情况(注意场景是1000个线程+100毫秒响应时间，每秒有10000个请求完成)，我们假设应答始终都是平稳的，只是请求不平稳，第一个10毫秒只有50,第二个10毫秒有150： 下一个10毫秒，有100个连接结束请求回收连接到连接池，但是假设此时请求不均匀10毫秒内没有预计的100个请求进来，而是只有50个请求。注意此时连接池回收了100个连接又分配出去50个连接，因此连接池内有50个空闲连接。 然后注意看keepalive=10的设置，这意味着连接池中最多容许保留有10个空闲连接。因此nginx不得不将这50个空闲连接中的40个关闭，只留下10个。 再下一个10个毫秒，有150个请求进来，有100个请求结束任务释放连接。150 - 100 = 50,空缺了50个连接，减掉前面连接池保留的10个空闲连接，nginx不得不新建40个新连接来满足要求。 C、同样，如果假设相应不均衡也会出现上面的连接数波动情况。 造成连接数量反复震荡的一个推手，就是这个keepalive 这个最大空闲连接数。毕竟连接池中的1000个连接在频繁利用时，出现短时间内多余10个空闲连接的概率实在太高。因此为了避免出现上面的连接震荡，必须考虑加大这个参数，比如上面的场景如果将keepalive设置为100或者200,就可以非常有效的缓冲请求和应答不均匀。 总结：keepalive 这个参数一定要小心设置，尤其对于QPS比较高的场景，推荐先做一下估算，根据QPS和平均响应时间大体能计算出需要的长连接的数量。比如前面10000 QPS和100毫秒响应时间就可以推算出需要的长连接数量大概是1000. 然后将keepalive设置为这个长连接数量的10%到30%。比较懒的同学，可以直接设置为keepalive=1000之类的，一般都OK的了。 3、综上，出现大量TIME_WAIT的情况1）导致 nginx端出现大量TIME_WAIT的情况有两种： keepalive_requests设置比较小，高并发下超过此值后nginx会强制关闭和客户端保持的keepalive长连接；（主动关闭连接后导致nginx出现TIME_WAIT） keepalive设置的比较小（空闲数太小），导致高并发下nginx会频繁出现连接数震荡（超过该值会关闭连接），不停的关闭、开启和后端server保持的keepalive长连接； 2）导致后端server端出现大量TIME_WAIT的情况：nginx没有打开和后端的长连接，即：没有设置proxy_http_version 1.1;和proxy_set_header Connection “”;从而导致后端server每次关闭连接，高并发下就会出现server端出现大量TIME_WAIT 三、nginx配置https1、配置 123456789101112131415161718server &#123; listen 80 default_server; listen 443 ssl; server_name toutiao.iqiyi.com toutiao.qiyi.domain m.toutiao.iqiyi.com; root /data/none; index index.php index.html index.htm; ###ssl settings start ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_certificate /usr/local/nginx/conf/server.pem; ssl_certificate_key /usr/local/nginx/conf/server.key; ssl_session_cache shared:SSL:10m; ssl_session_timeout 10m; ssl_ciphers ALL:!kEDH!ADH:RC4+RSA:+HIGH:+EXP; ssl_prefer_server_ciphers on; ###ssl settings end… 2、性能比较：通过https访问Nginx一般会比http访问慢30%（https方式访问主要是耗Nginx服务器的cpu）通过下面实验验证： nginx后端挂了5台java服务器，java服务器中有个简单的java程序，从redis缓存随机读取一个value值输出到前端；（挂的java服务器越多，对nginx压力越大） 压测nginx，3000并发，一共请求30000次，返回结果都是200的情况下进行对比；实验结果：A、服务器负载对比：https访问，服务器cpu最高可以达到20%，而http的访问，服务器cpu基本在1%左右；无论那种访问，nginx服务器负载、内存都不高；B、nginx吞吐量对比（qps）：• https访问，30000次请求花了28s；（是http的3倍）• http访问，30000次请求花了9s； 统计qps时，每次清空nginx日志，然后加压，执行完毕后使用如下命令查看qps： 12# cat log.2.3000https | grep &apos;/api/news/v1/info?newsId=&apos; | awk &apos;&#123;print$3&#125;&apos;| uniq | wc -l37 注：不能持续加压，否则无限加大压力后往往是后端java服务出现瓶颈，导致返回给nginx的响应变慢，从而使得nginx压力变小。 3、优化：Nginx默认使用DHE算法来产生密匙，该加密算法效率很低。可以通过如下命令，删掉了kEDH算法。ssl_ciphers ALL:!kEDH!ADH:RC4+RSA:+HIGH:+EXP;]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx keepalive nopush sendfile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pm2简介]]></title>
    <url>%2F2017%2F10%2F13%2Fpm2%2F</url>
    <content type="text"><![CDATA[一、什么是pm2PM2是node进程管理工具，可以利用它来简化很多node应用管理的繁琐任务，如性能监控、自动重启、负载均衡等，而且使用非常简单。 二、pm2的安装全局安装，简直不能更简单。一行代码搞定：npm install -g pm2 1、目录介绍pm2安装好后，会自动在运行目录创建下面文件。 $HOME/.pm2 ：will contain all PM2 related files $HOME/.pm2/logs ：will contain all applications logs $HOME/.pm2/pids ：will contain all applications pids $HOME/.pm2/pm2.log ：PM2 logs $HOME/.pm2/pm2.pid ： PM2 pid $HOME/.pm2/rpc.sock ： Socket file for remote commands $HOME/.pm2/pub.sock ： Socket file for publishable events $HOME/.pm2/conf.js ： PM2 Configuration 2、入门教程拿express应用来举例。一般我们都是通过npm start启动应用：node ./bin/main.js。那么，换成pm2就是：pm2 start ./bin/www –watch （注意，这里用了--watch参数，意味着当你的express应用代码发生变化时，pm2会帮你重启服务） pm2的门槛很低，实在是没什么好讲的，详细请自行参阅文档。 官方文档：http://pm2.keymetrics.io/docs/usage/quick-start 三、常用命令1、启动参数说明： --watch：监听应用目录的变化，一旦发生变化，自动重启。如果要精确监听、不见听的目录，最好通过配置文件。 -i --instances：启用多少个实例，可用于负载均衡。如果-i 0或者-i max，则根据当前机器核数确定实例数目。 --ignore-watch：排除监听的目录/文件，可以是特定的文件名，也可以是正则。比如--ignore-watch=&quot;test node_modules &quot;some scripts&quot;&quot; -n --name：应用的名称。查看应用信息的时候可以用到。 -o --output &lt;path&gt;：标准输出日志文件的路径。 -e --error &lt;path&gt;：错误输出日志文件的路径。 --interpreter &lt;interpreter&gt;：the interpreter pm2 should use for executing app (bash, python…)。比如你用的coffee script来编写应用。 完整命令行参数列表：http://pm2.keymetrics.io/docs/usage/quick-start/#options 1（ci的nodejs工程部署目前还只能支持start命令的启动方式） 2、重启pm2 restart app.js pm2 reload app.js pm2 gracefulReload app.js (推荐) 3、停止(停止特定的应用。可以先通过pm2 list获取应用的名字（–name指定的）或者进程id。) 1pm2 stop app_name|app_id 如果要停止所有应用，可以 1pm2 stop all 4、查看进程状态1pm2 list 1pm2 prettylist (推荐) 5、查看某个进程的信息pm2 describe 0(pm_id) 四、配置文件1、简单说明 配置文件里的设置项，跟命令行参数基本是一一对应的。 可以选择yaml或者json文件，就看个人洗好了。（个人推荐：json格式的配置文件，pm2当作普通的js文件来处理，所以可以在里面添加注释或者编写代码，这对于动态调整配置很有好处。） 如果启动的时候指定了配置文件，那么命令行参数会被忽略。（个别参数除外，比如–env） 2、例子举个简单例子，完整配置说明请参考官方文档：http://pm2.keymetrics.io/docs/usage/pm2-doc-single-page/ 12345678910111213141516171819202122&#123; &quot;name&quot;: &quot;node-test&quot;, &quot;log_date_format&quot;: &quot;YYYY-MM-DD HH:mm:ss SSS&quot;, &quot;script&quot;: &quot;./build/main.js&quot;, &quot;out_file&quot;: &quot;./var/log/app.log&quot;, &quot;error_file&quot;: &quot;./var/log/err.log&quot;, &quot;pid_file&quot;: &quot;./var/pid&quot;, &quot;watch&quot;: true, &quot;exec_mode&quot;: &quot;cluster&quot;, &quot;ignore_watch&quot;: [ &quot;var&quot;, &quot;public&quot;, &quot;test&quot;, &quot;.git&quot;, &quot;node_modules&quot; ], &quot;env&quot;: &#123; &quot;NODE_ENV&quot;: &quot;production&quot;, &quot;PORT&quot;: &quot;9101&quot; &#125;, &quot;node_args&quot;: &quot;--harmony&quot;&#125; 五、pm2有什么特点？1、自动重启pm2 start app.js --watch 监控整个项目的文件，如果只想监听指定文件和目录，建议通过配置文件的watch、ignore_watch字段来设置。 建议直接看文档：http://pm2.keymetrics.io/docs/usage/watch-and-restart/#auto-restart-apps-on-file-change 2、环境切换在实际项目开发中，我们的应用经常需要在多个环境下部署，比如开发环境、测试环境、生产环境等。在不同环境下，有时候配置项会有差异，比如链接的数据库地址不同等。 对于这种场景，pm2可以很好支持的。首先通过在配置文件中通过env_xx来声明不同环境的配置，然后在启动应用时，通过--env参数指定运行的环境。 环境配置声明首先，在配置文件中，通过env选项声明多个环境配置。简单说明下： env为默认的环境配置（生产环境），env_dev、env_test则分别是开发、测试环境。可以看到，不同环境下的NODE_ENV、REMOTE_ADDR字段的值是不同的。 在应用中，可以通过process.env.REMOTE_ADDR等来读取配置中生命的变量。 &quot;env&quot;: { &quot;NODE_ENV&quot;: &quot;production&quot;, &quot;REMOTE_ADDR&quot;: &quot;http://www.example.com/&quot; }, &quot;env_dev&quot;: { &quot;NODE_ENV&quot;: &quot;development&quot;, &quot;REMOTE_ADDR&quot;: &quot;http://wdev.example.com/&quot; }, &quot;env_test&quot;: { &quot;NODE_ENV&quot;: &quot;test&quot;, &quot;REMOTE_ADDR&quot;: &quot;http://wtest.example.com/&quot; } 启动指明环境通过下面启动脚本（开发环境），那么，此时process.env.REMOTE_ADDR的值就是相应的 http://wdev.example.com/ ，可以自己试验下。 1pm2 start app.js --env dev 3、负载均衡命令如下，表示开启三个进程。（如果-i 0，则会根据机器当前核数自动开启尽可能多的进程。） 12pm2 start app.js -i 3 # 开启三个进程pm2 start app.js -i max # 根据机器CPU核数，开启对应数目的进程，目前不推荐，推荐使用 -i 0 参考文档：http://pm2.keymetrics.io/docs/usage/cluster-mode/#automatic-load-balancing 4、日志查看除了可以打开日志文件查看日志外，还可以通过pm2 logs来查看实时日志。这点对于线上问题排查非常重要。 比如某个node服务突然异常重启了，那么可以通过pm2提供的日志工具来查看实时日志，看是不是脚本出错之类导致的异常重启。 pm2 logs]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown常用总结]]></title>
    <url>%2F2017%2F10%2F06%2Fmarkdown%2F</url>
    <content type="text"><![CDATA[Markdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档，然后转换成格式丰富的HTML页面。 —— 维基百科 正如您在阅读的这份文档，它使用简单的符号标识不同的标题，将某些文字标记为粗体或者斜体，创建一个链接或一个脚注[^demo]。下面列举了几个高级功能，更多语法请按Ctrl + /查看帮助。 代码块 12345678910@requires_authorizationdef somefunc(param1='', param2=0): '''A docstring''' if param1 &gt; param2: # interesting print 'Greater' return (param2 - param1 + 1) or Noneclass SomeClass: pass&gt;&gt;&gt; message = '''interpreter... prompt''' LaTeX 公式可以创建行内公式，例如 $\Gamma(n) = (n-1)!\quad\forall n\in\mathbb N$。或者块级公式： $$ x = \dfrac{-b \pm \sqrt{b^2 - 4ac}}{2a} $$ 表格 Item Value Qty Computer 1600 USD 5 Phone 12 USD 12 Pipe 1 USD 234 流程图 12345678st=&gt;start: Starte=&gt;endop=&gt;operation: My Operationcond=&gt;condition: Yes or No?st-&gt;op-&gt;condcond(yes)-&gt;econd(no)-&gt;op 以及时序图: 123Alice-&gt;Bob: Hello Bob, how are you?Note right of Bob: Bob thinksBob--&gt;Alice: I am good thanks! 提示：想了解更多，请查看流程图[语法][3]以及时序图[语法][4]。 复选框使用 - [ ] 和 - [x] 语法可以创建复选框，实现 todo-list 等功能。例如： 已完成事项 待办事项1 待办事项2 注意：目前支持尚不完全。 添加图片1![Alt text](/images/img.jpg) 这个图片的链接为: http://xxx.xxx/images/img.jpg]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
</search>
